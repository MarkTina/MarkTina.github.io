<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>笔趣阁网站小说爬取 | Gridea</title>
<link rel="shortcut icon" href="https://marktina.github.io//favicon.ico?v=1619539816433">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://marktina.github.io//styles/main.css">
<link rel="alternate" type="application/atom+xml" title="笔趣阁网站小说爬取 | Gridea - Atom Feed" href="https://marktina.github.io//atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="一、目标网站
www.xbiquge.cc
二、结构分析
这种类型的网站，结构上基本上大同小异，没什么难点。
随便点击一本小说目录url：
https://www.xbiquge.cc/book/52318/
随便点击一章小说目录url：
..." />
    <meta name="keywords" content="python爬虫" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://marktina.github.io/">
  <img class="avatar" src="https://marktina.github.io//images/avatar.png?v=1619539816433" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              笔趣阁网站小说爬取
            </h2>
            <div class="post-info">
              <span>
                2021-04-27
              </span>
              <span>
                3 min read
              </span>
              
                <a href="https://marktina.github.io/tag/Nzbrg9fOF/" class="post-tag">
                  # python爬虫
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://marktina.github.io//post-images/bi-qu-ge-wang-zhan-xiao-shuo-pa-qu.jpg" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h1 id="一-目标网站">一、目标网站</h1>
<p>www.xbiquge.cc</p>
<h1 id="二-结构分析">二、结构分析</h1>
<p>这种类型的网站，结构上基本上大同小异，没什么难点。</p>
<p>随便点击一本小说目录url：<br>
https://www.xbiquge.cc/book/52318/</p>
<p>随便点击一章小说目录url：<br>
https://www.xbiquge.cc/book/52318/34917539.html</p>
<p>直接看目录的结构：<br>
<img src="https://marktina.github.io//post-images/1619538587555.jpg" alt="" loading="lazy"><br>
可以看见每一章的链接都隐藏在章节内的<code>&lt;a&gt;</code>标签内；</p>
<p>查看每章小说内的内容<br>
<img src="https://marktina.github.io//post-images/1619538744263.jpg" alt="" loading="lazy"><br>
都放置在一个 <code>&lt;div&gt;</code>内；</p>
<h1 id="三-爬取思路">三、爬取思路</h1>
<p>1.首选进入输入目标小说的目录 url ，获取所有章节的地址，并对章节名称，序位做标记；<br>
2.多线程或者多进程爬取每章小说的正文内容；<br>
3.生成每一章节的 txt 文本，已【序位-章节名】的命名格式保存；</p>
<h1 id="四-代码实现">四、代码实现</h1>
<pre><code class="language-python">import requests
import bs4
import re
import concurrent.futures
import os


def get_txt(t):
    # 元组拆包
    title, url = t[0], t[1]
    # 检验该内容是否已下载
    if os.path.exists(title):
        print(title, '已存在')
    # 获取url内的正文
    else:
        s = requests.get(url, headers).content
        soup = bs4.BeautifulSoup(s, 'lxml')
        txt = soup.find('div', id='content').text
        # 替换特殊符号
        p1 = re.compile('    ')
        # 替换掉笔趣阁广告部分
        p2 = re.compile('笔趣阁.*?！')
        txt = p1.sub('\n    ', txt)
        txt = p2.sub(' ', txt)
        # 正文第一行对标题做处理
        txt = title.replace('.txt', '') + '\n' + txt
        with open(title, 'w', encoding=&quot;utf-8&quot;) as f:
            f.write(txt)
        print(title, ' 下载完成')


def get_all_url(url='https://www.xbiquge.cc/book/4772/'):
    # 根据输入的小说目录地址，获取所有章节url
    s = requests.get(url, headers).content
    soup = bs4.BeautifulSoup(s, 'lxml')
    url_list = soup.find('dl').find_all('dd')
    u_l = []
    for i in url_list:
            # 以元组的方式保存章节名称及url
            try:
                u_l.append((i.find('a')['href'][:-5] + '-' + i.find('a').text.replace(' ', '-') + '.txt', url + i.find('a')['href']))
            except:
                pass
    print('获得所有章节链接')
    # 返回集合去重，因为目录内 最近跟新部分 和 所有章节部分有重复；
    u_l = set(u_l)
    return u_l


def threading_start_function(url_list):
    # 建立线程池，并分配线程任务
    with concurrent.futures.ThreadPoolExecutor() as executor:
        executor.map(get_txt, url_list)


def main():
    print('--------------------------------------------------\n'
          '1.下载   https://www.xbiquge.cc/   网站下的图书，才可使用本脚本\n'
          '2.若下载章节过多，速度变慢，关闭程序，重新开始下载，即可下载剩余部分\n'
          '--------------------------------------------------\n')
    mulu = input('\n请在下方输入目录链接\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n')
    u_l = list(get_all_url(mulu))
    print('获得小说章数: ', len(u_l), '\n马上开始下载')
    print(u_l)
    threading_start_function(u_l)
    print('\n\n下载完成\n\n')


if __name__ == '__main__':
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.128 Safari/537.36'}
    main()
</code></pre>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#%E4%B8%80-%E7%9B%AE%E6%A0%87%E7%BD%91%E7%AB%99">一、目标网站</a></li>
<li><a href="#%E4%BA%8C-%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90">二、结构分析</a></li>
<li><a href="#%E4%B8%89-%E7%88%AC%E5%8F%96%E6%80%9D%E8%B7%AF">三、爬取思路</a></li>
<li><a href="#%E5%9B%9B-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0">四、代码实现</a></li>
</ul>

              </div>
            </div>
          </article>
        </div>

        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://marktina.github.io//atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
